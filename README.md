# Automated Message Queue Monitoring and Recovery System

This project is a demonstration of a robust, two-part shell scripting system designed to monitor a database message queue for backlogs and perform a series of automated recovery actions. It was originally developed to solve a recurring operational issue, reducing manual intervention and improving system reliability.

## The Problem

In a message-driven architecture, it's common for processing listeners to hang or for specific "poison pill" messages to get stuck, causing a backlog in the database queue. This leads to processing delays and potential data discrepancies. Manual intervention was often required, which was slow, prone to human error, and required 24/7 monitoring.

This automation was built to:
1.  **Proactively detect** when the message queue backlog is growing or stuck.
2.  **Intelligently attempt** a series of escalating recovery steps without human intervention.
3.  **Alert** the support team only when automated recovery fails, providing them with a clear status.

## How It Works

The system uses two interconnected scripts running on a cron schedule:

1.  **`validation_script.sh` (The Detector):**
    *   Runs frequently (e.g., every 5-10 minutes).
    *   Checks the current count of unprocessed messages in the queue.
    *   Waits for a few minutes.
    *   Checks the count again.
    *   Compares the initial and final counts to determine the queue's status:
        *   **Processing:** The count is decreasing.
        *   **Stuck:** The count is unchanged.
        *   **Increasing:** The count is growing.
        *   **Clear:** The count is zero.
    *   It writes a definitive status line to a shared log file (`backlog_message_validation.log`) and sends an informational email.

2.  **`automation_script.sh` (The Resolver):**
    *   Runs on a cron schedule shortly after the `validation_script`.
    *   Reads the **last line** of the log file generated by the `validation_script`.
    *   If the status is "Stuck" or "Increasing", it triggers a multi-stage recovery process.

### The Automated Recovery Flow

If a problem is detected, `automation_script.sh` executes the following logic:

1.  **Check Listener Status:** Ensures the primary message processing listener is running. If not, it attempts to start it.
2.  **Initial Action - Reprocess Batches:**
    *   It queries the database for the top 4 stuck `batch_seq` identifiers.
    *   It calls a specific HTTP endpoint (a re-processing URL) for each batch ID to force them to be re-processed.
3.  **Validation (Round 1):** It monitors the queue count for several minutes.
    *   **If resolved,** it exits.
    *   **If improving,** it exits.
    *   **If still stuck,** it proceeds to the next stage.
4.  **Escalation - Bounce Listener:**
    *   It gracefully stops and restarts the message processing listener. This can clear hung states or memory issues.
    *   It re-runs the "Reprocess Batches" step.
5.  **Validation (Round 2):** It again monitors the queue count.
    *   **If resolved or improving,** it exits.
    *   **If still stuck,** it proceeds to the final stage.
6.  **Final Action - Alert for Manual Intervention:**
    *   The script concludes that automated recovery has failed.
    *   It sends a detailed email alert to the support team, including the current message count and a recommendation to investigate manually and disable the automation cron jobs to prevent repeated failed attempts.

## Making the Scripts Generic (Configuration)

To adapt these scripts for any environment, all hardcoded, system-specific values have been moved to a configuration section at the top of each script. You only need to modify these variables.

Below are the parts of the scripts that require changes, presented with placeholders.

### 1. Configuration Block

Instead of scattering environment variables and paths throughout the script, define them all in one place.
**Generic (Recommended):**
Place this block at the top of `automation_script.sh` and `validation_script.sh` and modify the values as needed.

```bash
#!/bin/bash

#======================================================
#               CONFIGURATION VARIABLES
#======================================================

# --- System & Application Paths ---
APP_HOME="/path/to/your/app/home"
ORACLE_HOME="/path/to/oracle/client"
JAVA_HOME="/path/to/java/jdk"
TNS_ADMIN="${APP_HOME}/config" # Path to tnsnames.ora
LISTENER_EXECUTABLE="${APP_HOME}/bin/my_listener_ctl"

# --- Logging ---
LOG_DIR="${APP_HOME}/logs"
VALIDATION_LOG_FILE="${LOG_DIR}/backlog_validation_status.log"
AUTOMATION_LOG_FILE="${LOG_DIR}/backlog_automation_process.log"

# --- Database & Application ---
DB_USER="your_db_user"
DB_PASSWORD="your_db_password" # Consider using an Oracle Wallet for production
DB_TNS_NAME="YOUR_TNS_ALIAS"
PROCESSING_URL="http://hostname:port/api/reprocess?id=" # URL to re-trigger a batch
LISTENER_PORT="9523" # Port your listener runs on
LOG_ERROR_PATTERN="Exception|OutOfMemory" # Pipe-separated error patterns in listener log

# --- Alerting ---
EMAIL_RECIPIENTS="your-team@example.com,another-team@example.com"
EMAIL_SUBJECT_PREFIX="[AUTOMATION] Message Queue"

# --- Behavior ---
# The age of a message in minutes to be considered "stuck"
STUCK_THRESHOLD_MINUTES=15
# Seconds to wait between checks in the validation script
VALIDATION_SLEEP_SECONDS=90

#======================================================
#               END OF CONFIGURATION
#======================================================

# Redirect all script output to the automation log
exec >> ${AUTOMATION_LOG_FILE} 2>&1

# Set Environment
export ORACLE_HOME
export TNS_ADMIN
export JAVA_HOME
export PATH=${ORACLE_HOME}/bin:${JAVA_HOME}/bin:/usr/bin:/bin:${APP_HOME}/bin

# ... rest of the script logic ...
```

### 2. Database Connection

Using the configuration variables makes the database calls clean and portable.

**Generic:**
```bash
DB_CONNECTION="${DB_USER}/${DB_PASSWORD}@${DB_TNS_NAME}"

MESSAGE_COUNT=$( sqlplus -s "${DB_CONNECTION}" <<EOF
set heading off
set feedback off
-- NOTE: Table and column names (sv_message_queue_hist, delete_ts, insert_ts)
-- must be changed to match your application's schema.
select count(*) from sv_message_queue_hist where delete_ts is null and insert_ts < sysdate - ${STUCK_THRESHOLD_MINUTES}/1440;
exit;
EOF
)
```

### 3. Application Interactions

Calls to the listener and reprocessing URL should use variables.

**Generic:**
```bash
${LISTENER_EXECUTABLE} start
netstat -an | grep "${LISTENER_PORT}" >/dev/null
curl "${PROCESSING_URL}${batch_seqs[$i]}"
```

## Prerequisites

*   A Bash shell environment.
*   Oracle SQL*Plus client installed and configured.
*   Standard command-line utilities: `netstat`, `curl`, `mail`.

## Setup and Usage

1.  **Configure:** Copy the scripts and update the **Configuration Variables** section at the top of each file to match your environment.
2.  **Permissions:** Make the scripts executable:
    ```sh
    chmod +x validation_script.sh
    chmod +x automation_script.sh
    ```
3.  **Schedule Cron Jobs:** Set up cron jobs to run the scripts. The `automation_script` should run a few minutes after the `validation_script` to ensure the log file is updated.

    **Example `crontab -e` entries:**
    ```cron
    # Run the validation script every 10 minutes
    */10 * * * * /path/to/your/scripts/validation_script.sh

    # Run the automation/recovery script every 10 minutes, at the 2-minute mark
    2,12,22,32,42,52 * * * * /path/to/your/scripts/automation_script.sh
    ```

---
> **Disclaimer:** This is a demonstration project. The logic and recovery steps are tailored to a specific use case. Please thoroughly test and adapt the scripts before deploying in a production environment. For instance, consider using a more secure method for database credentials, like Oracle Wallets, instead of plain text passwords.
